import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Generate a sample dataset
np.random.seed(42)
n_samples = 1000

data = {
    'monthly_usage_hours': np.random.uniform(0, 200, n_samples),
    'num_logins_per_month': np.random.randint(1, 50, n_samples),
    'subscription_length_months': np.random.randint(1, 60, n_samples),
    'customer_age': np.random.randint(18, 80, n_samples),
    'is_churn': np.random.choice([0, 1], size=n_samples, p=[0.85, 0.15])  # 15% churn rate
}

df = pd.DataFrame(data)

# Extract features and labels
X = df.drop(columns=['is_churn'])
y = df['is_churn']

# Standardize numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train a model (choose one: Logistic Regression, Random Forest, or Gradient Boosting)
model = RandomForestClassifier()  # Change to LogisticRegression() or GradientBoostingClassifier() if needed
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print(classification_report(y_test, y_pred))
